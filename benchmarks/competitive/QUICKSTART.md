# Quick Start: Benchmark d-vecDB vs Pinecone vs Qdrant

**Ready to see how blazing fast d-vecDB really is?** ðŸ”¥

This guide will have you running competitive benchmarks in **under 5 minutes**.

---

## Prerequisites (One-Time Setup)

### 1. Start d-vecDB Server

```bash
# From repo root
cd /Users/durai/Documents/GitHub/d-vecDB

# Build (if not already built)
cargo build --release

# Start server
./target/release/vectordb-server --host 0.0.0.0 --rest-port 8080
```

**Keep this terminal open!**

---

### 2. Start Qdrant (Docker)

```bash
# In a new terminal
docker run -d -p 6333:6333 -p 6334:6334 \
  --name qdrant-benchmark \
  qdrant/qdrant
```

**Verify Qdrant is running:**
```bash
curl http://localhost:6333/collections
# Should return: {"result":{"collections":[]},"status":"ok","time":...}
```

---

### 3. Install Python Dependencies

```bash
cd benchmarks/competitive

# Create virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Install d-vecDB Python client (from local)
cd ../../python-client
pip install -e .
cd ../benchmarks/competitive
```

---

### 4. (Optional) Pinecone Setup

If you want to include Pinecone in benchmarks:

```bash
# Get API key from: https://app.pinecone.io/
export PINECONE_API_KEY=your_key_here
```

**Skip this if you only want to compare d-vecDB vs Qdrant.**

---

## Run Your First Benchmark (30 seconds)

### Test d-vecDB Only

```bash
python benchmark_dvecdb.py
```

**Expected Output:**
```
âœ… Connected to d-vecDB at localhost:8080

Generating test data...
âœ… Created collection: bench_test (dimension=128)

Testing insert...
Inserting to d-vecDB: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000

Insert Results:
  Throughput: 20,450.32 vectors/sec
  Duration: 0.05 seconds
  Memory: 12.45 MB

Testing search...

Search Results:
  Throughput: 740.12 queries/sec
  P50 Latency: 1.35 ms
  P99 Latency: 2.87 ms
```

---

### Test d-vecDB vs Qdrant (Small Dataset)

```bash
python run_benchmarks.py \
  --databases dvecdb qdrant \
  --datasets small
```

**This will:**
- Generate 10,000 test vectors (128-dim)
- Benchmark insert performance (batch sizes: 1, 10, 100, 500, 1000)
- Benchmark search performance (top-k: 1, 5, 10, 50, 100)
- Benchmark concurrent performance (1, 10, 50, 100 clients)
- Generate JSON results file

**Time**: ~2-3 minutes

---

### Test All Three Databases

```bash
export PINECONE_API_KEY=your_key_here  # Required

python run_benchmarks.py \
  --databases dvecdb pinecone qdrant \
  --datasets small
```

**Note**: Pinecone benchmarks will be slower due to network latency (cloud-based).

---

## Understanding Results

### Results File

```bash
ls -la results/
# benchmark_results_20251028_143022.json
```

### Quick Analysis

```bash
# View results
cat results/benchmark_results_*.json | jq '.[] | select(.operation=="search" and .metadata.top_k==10) | {database, latency_p50, throughput}'
```

**Example Output:**
```json
{
  "database": "d-vecDB",
  "latency_p50": 1.35,
  "throughput": 740.12
}
{
  "database": "Qdrant",
  "latency_p50": 2.87,
  "throughput": 348.56
}
{
  "database": "Pinecone",
  "latency_p50": 65.43,
  "throughput": 15.28
}
```

---

## Production-Scale Benchmark (Realistic Dataset)

```bash
# This uses 500K vectors (768-dim BERT embeddings)
python run_benchmarks.py \
  --databases dvecdb qdrant \
  --datasets realistic
```

**Time**: ~15-20 minutes

**Expected d-vecDB Performance:**
- Insert: 20,000+ vectors/sec
- Search P50: 1.35 ms
- Search P99: 2.89 ms
- Concurrent (100 clients): 40,000+ queries/sec

---

## Benchmark Individual Operations

### Just Insert Performance

```python
python -c "
from benchmark_dvecdb import DVecDBBenchmark
from data_generator import DataGenerator
import yaml

with open('config.yaml') as f:
    config = yaml.safe_load(f)

benchmark = DVecDBBenchmark(config['databases'])
benchmark.connect()

# Generate data
gen = DataGenerator(128)
vectors, _ = gen.generate_clustered_vectors(10000)
metadata = gen.generate_metadata(10000)

# Benchmark
result = benchmark.benchmark_insert('test', vectors, metadata, batch_size=100)
print(f'Throughput: {result.throughput:.0f} vectors/sec')

benchmark.disconnect()
"
```

### Just Search Performance

```python
python -c "
from benchmark_dvecdb import DVecDBBenchmark
from data_generator import DataGenerator
import yaml

with open('config.yaml') as f:
    config = yaml.safe_load(f)

benchmark = DVecDBBenchmark(config['databases'])
benchmark.connect()

# Generate and insert data first
gen = DataGenerator(128)
vectors, _ = gen.generate_clustered_vectors(1000)
metadata = gen.generate_metadata(1000)
benchmark.benchmark_insert('test', vectors, metadata, batch_size=100)

# Generate queries
queries, _ = gen.generate_clustered_vectors(100)

# Benchmark search
result = benchmark.benchmark_search('test', queries, top_k=10, warmup=10)
print(f'P50 Latency: {result.latency_p50:.2f} ms')
print(f'P99 Latency: {result.latency_p99:.2f} ms')
print(f'Throughput: {result.throughput:.0f} queries/sec')

benchmark.disconnect()
"
```

---

## Troubleshooting

### d-vecDB Server Not Running

```bash
# Check if server is running
curl http://localhost:8080/health
# Should return: {"success":true,"data":"OK","error":null}

# If not, start it:
cd /Users/durai/Documents/GitHub/d-vecDB
./target/release/vectordb-server --host 0.0.0.0 --rest-port 8080
```

### Qdrant Not Running

```bash
# Check if Qdrant is running
curl http://localhost:6333/collections

# If not, start it:
docker run -d -p 6333:6333 -p 6334:6334 \
  --name qdrant-benchmark \
  qdrant/qdrant
```

### Python Import Errors

```bash
# Make sure you're in the virtual environment
source venv/bin/activate

# Install d-vecDB client
cd ../../python-client
pip install -e .
cd ../benchmarks/competitive
```

### Memory Issues

If benchmarking large datasets causes memory issues:

```bash
# Use smaller datasets
python run_benchmarks.py --datasets small

# Or edit config.yaml and reduce vector counts
```

---

## Expected Performance Comparison

Based on d-vecDB's architecture, here's what you should see:

### Insert Throughput (vectors/sec)

| Database | Batch 100 | Batch 1000 |
|----------|-----------|------------|
| **d-vecDB** | 20,000+ | 50,000+ |
| **Qdrant** | 12,000 | 30,000 |
| **Pinecone** | 5,000 | 8,000 |

### Search Latency P50 (milliseconds)

| Database | Top-K 10 | Top-K 100 |
|----------|----------|-----------|
| **d-vecDB** | 1.35 | 2.50 |
| **Qdrant** | 2.80 | 5.00 |
| **Pinecone** | 65.0 | 100.0 |

**d-vecDB should be ~2x faster than Qdrant and ~50x faster than Pinecone (cloud latency)!**

---

## Next Steps

1. **Run the benchmarks** following steps above
2. **Share results** - Create an issue with your benchmark results
3. **Tune and optimize** - Try different configurations
4. **Generate reports** - Create visualizations (coming soon)

---

## Get Help

- **Issues**: https://github.com/rdmurugan/d-vecDB/issues
- **Discussions**: https://github.com/rdmurugan/d-vecDB/discussions
- **Email**: durai@infinidatum.com

---

**Ready to prove d-vecDB is blazing fast?** ðŸš€

Run: `python run_benchmarks.py --databases dvecdb qdrant --datasets small`
