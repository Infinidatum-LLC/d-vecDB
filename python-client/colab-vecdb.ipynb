{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "installation",
        "cleanup"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üöÄ d-vecDB Python Client - Google Colab Example (UPDATED & FIXED)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rdmurugan/d-vecDB/blob/master/python-client/colab-vecdb.ipynb)\n",
        "\n",
        "## üéâ This is a comprehensive, working example for Google Colab!\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT: Before running, update the `SERVER_HOST` variable in the configuration cell with your actual ngrok URL!**\n",
        "\n",
        "### ‚úÖ All known issues have been fixed:\n",
        "- Vector field: `values` ‚Üí `data`\n",
        "- Method: `upsert_vectors` ‚Üí `insert_vectors`  \n",
        "- Method: `search_vectors` ‚Üí `search`\n",
        "- Parameter: `top_k` ‚Üí `limit`\n",
        "- Field: `score` ‚Üí `distance`\n",
        "- Proper SSL configuration for ngrok HTTPS\n",
        "- Correct error handling and response parsing\n",
        "\n",
        "### üìã Prerequisites:\n",
        "1. A running d-vecDB server\n",
        "2. ngrok tunnel (if using local server) \n",
        "3. Update `SERVER_HOST` variable below\n",
        "\n",
        "### üöÄ Ready to run in Google Colab!\n",
        "\n",
        "---\n",
        "\n",
        "## What you'll learn:\n",
        "- How to install and set up d-vecDB client in Colab\n",
        "- Connect to a remote d-vecDB server\n",
        "- Create collections and insert vectors\n",
        "- Perform similarity searches\n",
        "- Work with text embeddings using sentence transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "installation"
      },
      "source": [
        "## üîß Installation\n",
        "\n",
        "First, let's install the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install the d-vecDB Python client and dependencies\n",
        "# Specify compatible versions for grpcio and protobuf to avoid AttributeError\n",
        "!pip install vectordb-client sentence-transformers numpy pandas matplotlib grpcio==1.62.2 grpcio-tools==1.62.2 protobuf==4.25.3\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngrok_setup"
      },
      "source": [
        "### üåê Optional: ngrok Setup\n",
        "\n",
        "If you're running your own d-vecDB server locally, uncomment the cells below to set up ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngrok_install"
      },
      "outputs": [],
      "source": [
        "# Optional: Set up ngrok if you want to expose a local server\n",
        "# Uncomment the lines below if you're running your own d-vecDB server locally\n",
        "# !pip install pyngrok\n",
        "# !ngrok config add-authtoken YOUR_NGROK_TOKEN_HERE\n",
        "# from pyngrok import ngrok\n",
        "# public_url = ngrok.connect(8080)\n",
        "# print(f\"üåê Your ngrok URL: {public_url}\")\n",
        "print(\"‚ÑπÔ∏è  Using existing ngrok URL - update SERVER_HOST below with your actual URL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "client_setup"
      },
      "source": [
        "## üöÄ Setting up the VectorDB Client\n",
        "\n",
        "**Note**: For this example, you'll need access to a running d-vecDB server. You can:\n",
        "1. Run a local server and use ngrok to expose it\n",
        "2. Use a cloud-hosted d-vecDB instance\n",
        "3. For demo purposes, we'll show how to set up the client (you'll need to replace with your actual server details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_client"
      },
      "outputs": [],
      "source": [
        "from vectordb_client import VectorDBClient\n",
        "from vectordb_client.types import (\n",
        "    CollectionConfig, Vector, DistanceMetric,\n",
        "    IndexConfig, VectorType\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "configuration"
      },
      "outputs": [],
      "source": [
        "# Configuration - Replace with your actual ngrok URL\n",
        "SERVER_HOST = \"your-ngrok-url.ngrok-free.app\"  # ‚ö†Ô∏è CHANGE THIS to your actual ngrok host\n",
        "SERVER_PORT = 443  # HTTPS port for ngrok (not 8080)\n",
        "\n",
        "# For other ngrok URLs, it would look like:\n",
        "# SERVER_HOST = \"abc123.ngrok-free.app\"\n",
        "# SERVER_PORT = 443\n",
        "\n",
        "print(f\"üîß Configuration:\")\n",
        "print(f\"üåê Server: {SERVER_HOST}:{SERVER_PORT}\")\n",
        "print(f\"üîí SSL: True (required for ngrok HTTPS)\")\n",
        "\n",
        "if SERVER_HOST == \"your-ngrok-url.ngrok-free.app\":\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: Please update SERVER_HOST with your actual ngrok URL before proceeding!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "connect_to_server"
      },
      "outputs": [],
      "source": [
        "print(f\"üîå Connecting to d-vecDB server at {SERVER_HOST}:{SERVER_PORT}...\")\n",
        "\n",
        "try:\n",
        "    # Initialize the client with SSL support for ngrok\n",
        "    client = VectorDBClient(\n",
        "        host=SERVER_HOST,\n",
        "        port=SERVER_PORT,\n",
        "        ssl=True,        # Required for ngrok HTTPS URLs\n",
        "        protocol=\"rest\"\n",
        "    )\n",
        "\n",
        "    # Test the connection with correct method name\n",
        "    health_response = client.health_check()  # Changed from ping()\n",
        "\n",
        "    if health_response and health_response.success:\n",
        "        print(\"‚úÖ Successfully connected to d-vecDB!\")\n",
        "\n",
        "        # Get server statistics with correct method name\n",
        "        server_stats = client.get_server_stats()  # Changed from get_server_info()\n",
        "        print(f\"üìä Server Stats: {server_stats}\")\n",
        "\n",
        "        # List existing collections\n",
        "        collections = client.list_collections()\n",
        "        print(f\"üìÇ Collections: {collections.data}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Could not connect to d-vecDB server\")\n",
        "        print(\"Please check your server configuration and try again.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Connection failed: {e}\")\n",
        "    print(f\"Error type: {type(e).__name__}\")\n",
        "    print(\"\\nüí° Make sure you have:\")\n",
        "    print(\"1. A running d-vecDB server\")\n",
        "    print(\"2. Active ngrok tunnel pointing to your server\")\n",
        "    print(\"3. Correct configuration:\")\n",
        "    print(f\"   - Host: {SERVER_HOST}\")\n",
        "    print(f\"   - Port: {SERVER_PORT} (443 for HTTPS)\")\n",
        "    print(\"   - SSL: True (required for ngrok HTTPS)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sample_data"
      },
      "source": [
        "## üìÑ Preparing Sample Data\n",
        "\n",
        "Let's create some sample documents and generate embeddings for them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_sample_documents"
      },
      "outputs": [],
      "source": [
        "# Sample documents for demonstration\n",
        "sample_documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"Machine learning is a subset of artificial intelligence\",\n",
        "    \"Vector databases enable efficient similarity search\",\n",
        "    \"Python is a popular programming language for data science\",\n",
        "    \"Natural language processing helps computers understand text\",\n",
        "    \"Deep learning models can generate realistic images\",\n",
        "    \"Cloud computing provides scalable infrastructure solutions\",\n",
        "    \"Database optimization improves query performance\",\n",
        "    \"Artificial neural networks mimic biological brain functions\",\n",
        "    \"Big data analytics reveals insights from large datasets\"\n",
        "]\n",
        "\n",
        "print(f\"üìö Sample documents ({len(sample_documents)} total):\")\n",
        "for i, doc in enumerate(sample_documents, 1):\n",
        "    print(f\"{i:2d}. {doc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "embeddings"
      },
      "source": [
        "## üî§ Generating Text Embeddings\n",
        "\n",
        "We'll use sentence-transformers to convert our text documents into vector embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_embeddings"
      },
      "outputs": [],
      "source": [
        "# Initialize the sentence transformer model\n",
        "print(\"ü§ñ Loading sentence transformer model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight model, good for Colab\n",
        "\n",
        "# Generate embeddings\n",
        "print(\"‚ö° Generating embeddings...\")\n",
        "embeddings = model.encode(sample_documents)\n",
        "\n",
        "print(f\"‚úÖ Generated {len(embeddings)} embeddings\")\n",
        "print(f\"üìè Embedding dimension: {embeddings.shape[1]}\")\n",
        "print(f\"üî¢ Data type: {embeddings.dtype}\")\n",
        "\n",
        "# Convert to list format for d-vecDB\n",
        "embedding_vectors = [embedding.tolist() for embedding in embeddings]\n",
        "\n",
        "print(f\"\\nüìä First embedding preview (first 10 dimensions):\")\n",
        "print(embedding_vectors[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization"
      },
      "source": [
        "## üìà Visualizing Embeddings\n",
        "\n",
        "Let's visualize our embeddings in 2D using PCA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualize_embeddings"
      },
      "outputs": [],
      "source": [
        "# Reduce embeddings to 2D for visualization\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
        "                     alpha=0.7, s=100, c=range(len(sample_documents)),\n",
        "                     cmap='tab10')\n",
        "\n",
        "# Add labels for each point\n",
        "for i, doc in enumerate(sample_documents):\n",
        "    plt.annotate(f\"{i+1}\",\n",
        "                xy=(embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
        "                xytext=(5, 5), textcoords='offset points',\n",
        "                fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.title('Document Embeddings Visualization (PCA)', fontsize=16)\n",
        "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
        "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìã Document Reference:\")\n",
        "for i, doc in enumerate(sample_documents, 1):\n",
        "    print(f\"{i:2d}. {doc[:50]}{'...' if len(doc) > 50 else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_collection"
      },
      "source": [
        "## üìÅ Creating a Collection\n",
        "\n",
        "Now let's create a collection in d-vecDB to store our embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "collection_setup"
      },
      "outputs": [],
      "source": [
        "# Collection configuration\n",
        "collection_name = \"colab_text_embeddings\"\n",
        "embedding_dimension = len(embedding_vectors[0])\n",
        "\n",
        "print(f\"üìÅ Creating collection '{collection_name}'...\")\n",
        "\n",
        "try:\n",
        "    # Clean up any existing collection\n",
        "    try:\n",
        "        client.delete_collection(collection_name)\n",
        "        print(f\"üóëÔ∏è  Deleted existing collection\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Create new collection with cosine similarity\n",
        "    config = CollectionConfig(\n",
        "        name=collection_name,\n",
        "        dimension=embedding_dimension,\n",
        "        distance_metric=DistanceMetric.COSINE\n",
        "    )\n",
        "    response = client.create_collection(config)\n",
        "\n",
        "    print(f\"‚úÖ Created collection: {response}\")\n",
        "\n",
        "    # List all collections to verify\n",
        "    collections = client.list_collections()\n",
        "    print(f\"üìã Available collections: {collections}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to create collection: {e}\")\n",
        "    print(\"Please ensure your d-vecDB server is running and accessible.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "insert_vectors"
      },
      "source": [
        "## ‚¨ÜÔ∏è Inserting Vectors\n",
        "\n",
        "Let's insert our document embeddings into the collection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vector_insertion"
      },
      "outputs": [],
      "source": [
        "print(\"‚¨ÜÔ∏è  Inserting vectors into collection...\")\n",
        "\n",
        "try:\n",
        "    # Prepare vectors with metadata\n",
        "    vectors_to_insert = []\n",
        "\n",
        "    for i, (doc, embedding) in enumerate(zip(sample_documents, embedding_vectors)):\n",
        "        vector = Vector(\n",
        "            id=str(i + 1),\n",
        "            data=embedding,  # FIXED: Changed from 'values' to 'data'\n",
        "            metadata={\n",
        "                \"document\": doc,\n",
        "                \"length\": len(doc),\n",
        "                \"index\": i + 1,\n",
        "                \"word_count\": len(doc.split())\n",
        "            }\n",
        "        )\n",
        "        vectors_to_insert.append(vector)\n",
        "\n",
        "    # Insert vectors in batch\n",
        "    start_time = time.time()\n",
        "    response = client.insert_vectors(collection_name, vectors_to_insert)  # FIXED: Changed from 'upsert_vectors'\n",
        "    insert_time = time.time() - start_time\n",
        "\n",
        "    print(f\"‚úÖ Inserted {len(vectors_to_insert)} vectors in {insert_time:.2f} seconds\")\n",
        "    print(f\"üìä Insert response: {response}\")\n",
        "\n",
        "    # Get collection statistics\n",
        "    try:\n",
        "        stats = client.get_collection_stats(collection_name)\n",
        "        print(f\"üìà Collection stats: {stats}\")\n",
        "    except Exception as stats_error:\n",
        "        print(f\"‚ÑπÔ∏è  Collection stats not available: {stats_error}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to insert vectors: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "similarity_search"
      },
      "source": [
        "## üîç Similarity Search\n",
        "\n",
        "Now let's perform similarity searches to find related documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "search_function"
      },
      "outputs": [],
      "source": [
        "def search_similar_documents(query_text: str, top_k: int = 5):\n",
        "    \"\"\"Search for documents similar to the query text.\"\"\"\n",
        "    print(f\"\\nüîç Searching for: '{query_text}'\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # Generate embedding for query\n",
        "        query_embedding = model.encode([query_text])[0].tolist()\n",
        "\n",
        "        # Perform search\n",
        "        start_time = time.time()\n",
        "        results = client.search(\n",
        "            collection_name=collection_name,\n",
        "            query_vector=query_embedding,\n",
        "            limit=top_k  # FIXED: Changed from 'top_k' to 'limit'\n",
        "        )\n",
        "        search_time = time.time() - start_time\n",
        "\n",
        "        print(f\"‚ö° Search completed in {search_time:.3f} seconds\")\n",
        "        \n",
        "        if results.success and results.data:\n",
        "            print(f\"üìã Found {len(results.data)} results:\\n\")\n",
        "\n",
        "            for i, result in enumerate(results.data, 1):\n",
        "                doc_text = result.metadata.get('document', 'N/A')\n",
        "                similarity = 1 - result.distance  # Convert distance to similarity for cosine\n",
        "\n",
        "                print(f\"{i}. [Similarity: {similarity:.3f}] {doc_text}\")\n",
        "        else:\n",
        "            print(\"‚ùå No results found or search failed\")\n",
        "            print(f\"Response: {results}\")\n",
        "\n",
        "        return results.data if results.success else []\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Search failed: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example_searches"
      },
      "outputs": [],
      "source": [
        "# Example searches\n",
        "search_queries = [\n",
        "    \"artificial intelligence and machine learning\",\n",
        "    \"database and data storage\",\n",
        "    \"programming languages for data\",\n",
        "    \"computer vision and image processing\"\n",
        "]\n",
        "\n",
        "for query in search_queries:\n",
        "    search_similar_documents(query, top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive_search"
      },
      "source": [
        "## üéØ Interactive Search\n",
        "\n",
        "Try your own search queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_search"
      },
      "outputs": [],
      "source": [
        "# Interactive search - modify this cell to try different queries\n",
        "your_query = \"neural networks and AI\"  # ‚Üê Change this to your query\n",
        "\n",
        "print(\"üéØ Your custom search:\")\n",
        "results = search_similar_documents(your_query, top_k=5)\n",
        "\n",
        "# Show detailed results with metadata\n",
        "if results:\n",
        "    print(\"\\nüìä Detailed Results:\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for i, result in enumerate(results, 1):\n",
        "        similarity = 1 - result.distance  # FIXED: Changed from 'score' to 'distance'\n",
        "        metadata = result.metadata\n",
        "\n",
        "        print(f\"\\nResult {i}:\")\n",
        "        print(f\"  üìÑ Document: {metadata.get('document', 'N/A')}\")\n",
        "        print(f\"  üéØ Similarity: {similarity:.4f}\")\n",
        "        print(f\"  üìè Length: {metadata.get('length', 'N/A')} characters\")\n",
        "        print(f\"  üí¨ Words: {metadata.get('word_count', 'N/A')}\")\n",
        "        print(f\"  üÜî ID: {result.id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced_operations"
      },
      "source": [
        "## üîß Advanced Vector Operations\n",
        "\n",
        "Let's explore some advanced operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "advanced_ops"
      },
      "outputs": [],
      "source": [
        "print(\"üîß Advanced Vector Operations\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    # 1. Get collection info\n",
        "    print(\"\\n1Ô∏è‚É£ Getting collection information...\")\n",
        "    try:\n",
        "        collection_info = client.get_collection(collection_name)\n",
        "        print(f\"‚úÖ Collection info: {collection_info}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ÑπÔ∏è Collection info not available: {e}\")\n",
        "\n",
        "    # 2. Filter search with metadata\n",
        "    print(\"\\n2Ô∏è‚É£ Filtered search (documents with >50 characters)...\")\n",
        "    query_text = \"data science programming\"\n",
        "    query_embedding = model.encode([query_text])[0].tolist()\n",
        "\n",
        "    # Note: Metadata filtering syntax depends on your d-vecDB server implementation\n",
        "    # This is a conceptual example - adjust based on your server's API\n",
        "    filtered_results = client.search(\n",
        "        collection_name=collection_name,\n",
        "        query_vector=query_embedding,\n",
        "        limit=5\n",
        "        # filter={\"length\": {\"$gt\": 50}}  # Uncomment if your server supports filtering\n",
        "    )\n",
        "\n",
        "    if filtered_results.success and filtered_results.data:\n",
        "        print(f\"üìã Filtered results: {len(filtered_results.data)}\")\n",
        "        for result in filtered_results.data[:3]:\n",
        "            doc_length = result.metadata.get('length', 0)\n",
        "            if doc_length > 50:  # Client-side filtering as example\n",
        "                similarity = 1 - result.distance\n",
        "                print(f\"   ‚Ä¢ [Similarity: {similarity:.3f}, Length: {doc_length}] {result.metadata.get('document', 'N/A')[:60]}...\")\n",
        "    else:\n",
        "        print(\"‚ùå Filtered search failed\")\n",
        "\n",
        "    # 3. List collections\n",
        "    print(\"\\n3Ô∏è‚É£ Listing all collections...\")\n",
        "    all_collections = client.list_collections()\n",
        "    if all_collections.success:\n",
        "        print(f\"‚úÖ Found {len(all_collections.data)} collections: {all_collections.data}\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to list collections\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Advanced operations failed: {e}\")\n",
        "    print(\"Some operations may not be supported by your d-vecDB server version.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "performance_testing"
      },
      "source": [
        "## ‚ö° Performance Testing\n",
        "\n",
        "Let's test the performance of our vector database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "performance_test"
      },
      "outputs": [],
      "source": [
        "print(\"‚ö° Performance Testing\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "try:\n",
        "    # Test search performance\n",
        "    test_queries = [\n",
        "        \"machine learning algorithms\",\n",
        "        \"database optimization techniques\",\n",
        "        \"natural language processing\",\n",
        "        \"cloud computing infrastructure\",\n",
        "        \"artificial intelligence applications\"\n",
        "    ]\n",
        "\n",
        "    search_times = []\n",
        "\n",
        "    print(\"üîç Running search performance test...\")\n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        query_embedding = model.encode([query])[0].tolist()\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = client.search(\n",
        "            collection_name=collection_name,\n",
        "            query_vector=query_embedding,\n",
        "            limit=5\n",
        "        )\n",
        "        search_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
        "        search_times.append(search_time)\n",
        "        \n",
        "        result_count = len(results.data) if results.success and results.data else 0\n",
        "        print(f\"   Query {i}: {search_time:.2f}ms ({result_count} results)\")\n",
        "\n",
        "    # Performance statistics\n",
        "    avg_time = np.mean(search_times)\n",
        "    min_time = np.min(search_times)\n",
        "    max_time = np.max(search_times)\n",
        "\n",
        "    print(f\"\\nüìä Performance Summary:\")\n",
        "    print(f\"   Average search time: {avg_time:.2f}ms\")\n",
        "    print(f\"   Fastest search: {min_time:.2f}ms\")\n",
        "    print(f\"   Slowest search: {max_time:.2f}ms\")\n",
        "\n",
        "    # Visualize performance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(1, len(search_times) + 1), search_times, alpha=0.7)\n",
        "    plt.axhline(y=avg_time, color='r', linestyle='--', label=f'Average: {avg_time:.2f}ms')\n",
        "    plt.xlabel('Query Number')\n",
        "    plt.ylabel('Search Time (milliseconds)')\n",
        "    plt.title('Vector Search Performance')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Performance test failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup"
      },
      "source": [
        "## üßπ Cleanup\n",
        "\n",
        "Clean up resources when done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cleanup_resources"
      },
      "outputs": [],
      "source": [
        "print(\"üßπ Cleaning up resources...\")\n",
        "\n",
        "try:\n",
        "    # Optionally delete the collection\n",
        "    delete_collection = False  # Set to True if you want to clean up\n",
        "\n",
        "    if delete_collection:\n",
        "        response = client.delete_collection(collection_name)\n",
        "        print(f\"üóëÔ∏è  Deleted collection '{collection_name}': {response}\")\n",
        "    else:\n",
        "        print(f\"‚ÑπÔ∏è  Collection '{collection_name}' preserved for further use\")\n",
        "\n",
        "    # List remaining collections\n",
        "    collections = client.list_collections()\n",
        "    print(f\"üìã Remaining collections: {collections}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Cleanup failed: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Notebook execution completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "## üöÄ Next Steps\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "- ‚úÖ Set up d-vecDB client in Google Colab\n",
        "- ‚úÖ Generated text embeddings using sentence transformers\n",
        "- ‚úÖ Created a vector collection\n",
        "- ‚úÖ Inserted and searched vectors\n",
        "- ‚úÖ Performed similarity searches\n",
        "- ‚úÖ Tested performance\n",
        "\n",
        "### What to try next:\n",
        "\n",
        "1. **Scale up**: Try with larger datasets (1000+ documents)\n",
        "2. **Different embeddings**: Experiment with different sentence transformer models\n",
        "3. **Real data**: Use your own documents or datasets\n",
        "4. **Advanced features**: Explore filtering, metadata queries, and batch operations\n",
        "5. **Integration**: Connect with your applications or data pipelines\n",
        "\n",
        "### Useful Resources:\n",
        "\n",
        "- üìö [d-vecDB Documentation](https://github.com/rdmurugan/d-vecDB)\n",
        "- ü§ó [Sentence Transformers](https://www.sbert.net/)\n",
        "- üêç [Python Client API Reference](https://github.com/rdmurugan/d-vecDB/tree/master/python-client)\n",
        "\n",
        "### Need Help?\n",
        "\n",
        "- üêõ Report issues: [GitHub Issues](https://github.com/rdmurugan/d-vecDB/issues)\n",
        "- üí¨ Discussions: [GitHub Discussions](https://github.com/rdmurugan/d-vecDB/discussions)\n",
        "\n",
        "Happy vector searching! üéâ"
      ]
    }
  ]
}